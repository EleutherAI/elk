dataset: boolq_fr
templates:
  3e386463-1715-4578-9cba-07d11a0d3b61: !Template
    answer_choices: Faux ||| Vrai
    id: 3e386463-1715-4578-9cba-07d11a0d3b61
    jinja: "Passage: {{passage}}


      Après avoir lu ce passage, j'ai une question : {{question}}? Vrai ou faux?
      |||


      {% if answer != -1 %}
      {{answer_choices[answer]}}
      {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: after_reading
    reference: ''
  492f0f88-4370-46cd-839b-1de37a55aeda: !Template
    answer_choices: Non ||| Oui
    id: 492f0f88-4370-46cd-839b-1de37a55aeda
    jinja: "{{ passage }} \nQuestion : {{ question }}\nRéponse : ||| \n{% if answer !=\
      \ -1 %}\n{{ answer_choices[answer] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: GPT-3 Style
    reference: Same as Figure G29, p. 58 of the GPT-3 paper
  6cb6a026-c070-470a-b75d-bb8fdf424e35: !Template
    answer_choices: Non ||| Oui
    id: 6cb6a026-c070-470a-b75d-bb8fdf424e35
    jinja: "{{ passage }} \n\nAprès avoir lu cela, je me demande {{ question }} ? |||\n{% if\
      \ answer != -1 %}\n{{ answer_choices[answer] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: "I wonder\u2026"
    reference: ''
  7cf7acdf-e3a2-459f-a3e8-2e2d27dd6aa5: !Template
    answer_choices: Non ||| Oui
    id: 7cf7acdf-e3a2-459f-a3e8-2e2d27dd6aa5
    jinja: 'Texte : {{passage}}


      Répondez à la question oui/non suivante : {{question}}? Oui ou non? |||


      {% if answer != -1 %}
      {{answer_choices[answer]}}
      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: yes_no_question
    reference: ''
  7d21d974-0624-4d4f-9e8c-644e2d009cb5: !Template
    answer_choices: Non ||| Oui
    id: 7d21d974-0624-4d4f-9e8c-644e2d009cb5
    jinja: "{{ passage }} \n\nAprès avoir lu cela, pourriez-vous me dire {{ question }} ?\
      \ ||| {% if answer != -1 %}{{ answer_choices[answer] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: "could you tell me\u2026"
    reference: ''
  922d3e87-ac58-4731-84d1-f0a40e47afb5: !Template
    answer_choices: Non ||| Oui
    id: 922d3e87-ac58-4731-84d1-f0a40e47afb5
    jinja: "EXAMEN\n1. Répondez par oui ou non.\n\nDocument : {{passage}}\nQuestion : {{question}}?\
      \ ||| \n{% if answer != -1 %}\n{{answer_choices[answer]}}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: exam
    reference: ''
  9a1bf459-8047-437c-9def-f21e960429cc: !Template
    answer_choices: Non ||| Oui
    id: 9a1bf459-8047-437c-9def-f21e960429cc
    jinja: "Basé sur le passage suivant, {{ question }}?\n\n{{ passage }}\
      \ ||| \n\n{% if answer != -1 %}{{ answer_choices[answer] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: based on the following passage
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  9f4c6b0a-437b-40c0-b467-db4b7218d38d: !Template
    answer_choices: Faux ||| Vrai
    id: 9f4c6b0a-437b-40c0-b467-db4b7218d38d
    jinja: 'Exercice : lisez le texte et répondez à la question par Vrai ou Faux.


      Texte : {{passage}}

      Question : {{question}} ? |||


      {% if answer != -1 %}
      {{answer_choices[answer]}}
      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: exercise
    reference: ''
  b2b3cb60-d6e3-491c-a09a-8201e13e417e: !Template
    answer_choices: Non ||| Oui
    id: b2b3cb60-d6e3-491c-a09a-8201e13e417e
    jinja: '{{ passage }}

      Basé sur le passage précédent, {{ question }} ? |||
      {% if answer != -1 %}
      {{ answer_choices[answer]}}
      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: based on the previous passage
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  eb78772c-e81e-4b8a-a77b-b75efd1c212a: !Template
    answer_choices: Faux ||| Vrai
    id: eb78772c-e81e-4b8a-a77b-b75efd1c212a
    jinja: '{{passage}}


      Q : {{question}}? Vrai ou faux? |||


      {% if answer != -1 %}
      {{answer_choices[answer]}}
      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - fr
      metrics:
      - Accuracy
      original_task: true
    name: valid_binary
    reference: ''
