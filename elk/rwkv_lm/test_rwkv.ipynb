{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kyle-elk-rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/kyle/HF-MODEL/rwkv-4-pile-14b/models--BlinkDL--rwkv-4-pile-14b/snapshots/939b6851f96122b7b49bd00d446b3b49481214dd/RWKV-4-Pile-14B-20230213-8019.pth'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "download_path = hf_hub_download(repo_id=\"BlinkDL/rwkv-4-pile-1b5\", filename=\"RWKV-4-Pile-1B5-20220903-8040.pth\")\n",
    "print(\"Download path is \"  + download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 6\n",
      "\n",
      "Loading /home/kyle/HF-MODEL/rwkv-4-pile-1b5/models--BlinkDL--rwkv-4-pile-1b5/snapshots/6ea995eaa87a17af560c9b41ce1a3d92355c5a49/RWKV-4-Pile-1B5-20220903-8040.pth ...\n",
      "Strategy: (total 24+1=25 layers)\n",
      "* cuda [float16, float16], store 25 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  50277  2048 \n",
      "blocks.0.ln1.weight               f16   cuda:0   2048       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   2048       \n",
      "blocks.0.ln2.weight               f16   cuda:0   2048       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   2048       \n",
      "blocks.0.att.time_decay           f32   cuda:0   2048       \n",
      "blocks.0.att.time_first           f32   cuda:0   2048       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   2048       \n",
      "blocks.0.att.key.weight           f16   cuda:0   2048  2048 \n",
      "blocks.0.att.value.weight         f16   cuda:0   2048  2048 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   2048  2048 \n",
      "blocks.0.att.output.weight        f16   cuda:0   2048  2048 \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   2048       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   2048       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   2048  8192 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   2048  2048 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0   8192  2048 \n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.23.ln1.weight              f16   cuda:0   2048       \n",
      "blocks.23.ln1.bias                f16   cuda:0   2048       \n",
      "blocks.23.ln2.weight              f16   cuda:0   2048       \n",
      "blocks.23.ln2.bias                f16   cuda:0   2048       \n",
      "blocks.23.att.time_decay          f32   cuda:0   2048       \n",
      "blocks.23.att.time_first          f32   cuda:0   2048       \n",
      "blocks.23.att.time_mix_k          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_v          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_r          f16   cuda:0   2048       \n",
      "blocks.23.att.key.weight          f16   cuda:0   2048  2048 \n",
      "blocks.23.att.value.weight        f16   cuda:0   2048  2048 \n",
      "blocks.23.att.receptance.weight   f16   cuda:0   2048  2048 \n",
      "blocks.23.att.output.weight       f16   cuda:0   2048  2048 \n",
      "blocks.23.ffn.time_mix_k          f16   cuda:0   2048       \n",
      "blocks.23.ffn.time_mix_r          f16   cuda:0   2048       \n",
      "blocks.23.ffn.key.weight          f16   cuda:0   2048  8192 \n",
      "blocks.23.ffn.receptance.weight   f16   cuda:0   2048  2048 \n",
      "blocks.23.ffn.value.weight        f16   cuda:0   8192  2048 \n",
      "ln_out.weight                     f16   cuda:0   2048       \n",
      "ln_out.bias                       f16   cuda:0   2048       \n",
      "head.weight                       f16   cuda:0   2048 50277 \n",
      "[ -8.828125  -21.84375    -9.3671875 ...  -7.7070312  -4.8710938\n",
      "  -1.9775391]\n",
      "[ -8.8203125 -21.828125   -9.3515625 ...  -7.6992188  -4.8632812\n",
      "  -1.9716797]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "os.environ[\"RWKV_JIT_ON\"] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '0' # if '1' then use CUDA kernel for seq mode (much faster)\n",
    "from rwkv.model import RWKV                         # pip install rwkv\n",
    "model = RWKV(model='/home/kyle/HF-MODEL/rwkv-4-pile-1b5/models--BlinkDL--rwkv-4-pile-1b5/snapshots/6ea995eaa87a17af560c9b41ce1a3d92355c5a49/RWKV-4-Pile-1B5-20220903-8040.pth', strategy='cuda fp16')\n",
    "\n",
    "out, state = model.forward([187, 510, 1563, 310, 247], None)   # use 20B_tokenizer.json\n",
    "print(out.detach().cpu().numpy())                   # get logits\n",
    "out, state = model.forward([187, 510], None)\n",
    "out, state = model.forward([1563], state)           # RNN has state (use deepcopy if you want to clone it)\n",
    "out, state = model.forward([310, 247], state)\n",
    "print(out.detach().cpu().numpy())                   # same result as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast(tokenizer_file='20B_tokenizer.json')\n",
    "text = \"The following movie review expresses what sentiment? George P. Cosmatos\\' \\\"Rambo: First Blood Part II\\\" is pure wish-fulfillment. The United States clearly didn\\'t win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn\\'t appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \\\"We Were Soldiers\\\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \\\"Do we get to win this time?\\\" Yes, you do.\\n\\nnegative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([241, 2048])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return as tensor\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "out, state = model.forward(tokens[\"input_ids\"], None)\n",
    "state[-1].shape # torch.Size([241, 2048]) w/ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received a list of 120 tensors, each of shape torch.Size([241, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Received a list of {len(state)} tensors, each of shape {state[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return as list\n",
    "tokens = tokenizer(text)\n",
    "out, state = model.forward(tokens[\"input_ids\"], None)\n",
    "state[-1].shape # torch.Size([2048]) w/o tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received a list of 120 tensors, each of shape torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Received a list of {len(state)} tensors, each of shape {state[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3020, -0.3469, -0.0307,  ...,  0.1010,  0.0585, -0.1140],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -8.828125  -21.828125   -9.359375  ...  -7.7070312  -4.875\n",
      "  -1.9785156]\n"
     ]
    }
   ],
   "source": [
    "out, state = model.forward([187, 510, 1563, 310, 247], None)   # use 20B_tokenizer.json\n",
    "print(out.detach().cpu().numpy())                   # get logits\n",
    "out, state = model.forward([187, 510], None)\n",
    "out, state = model.forward([1563], state)           # RNN has state (use deepcopy if you want to clone it)\n",
    "out, state = model.forward([310, 247], state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "\n",
      "Scientists discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "\n",
      "This discovery is an amazing example of the effects of rapid evolution and natural selection. It is also interesting because it confirms that life can adapt to different environments.\n",
      "\n",
      "The population of these large dragons ranged from about 200 to about 600 in the area where they live. The most striking aspect of this dragon is its ability to rapidly change its vocalizations from \"coo\" to \"thud.\" The Tibetan dragon also has long claws that help it hunt on land and on water. They also are able to reach speeds of up to 50 kilometers per hour. The long and pointed snout allows them to grasp and consume their prey by crushing it between their teeth and then swallowing the flesh. Their tongue is able to carry food items that they swallow whole, such as fruit, seeds, insects, worms,"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nScientists discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\\n\\nThis discovery is an amazing example of the effects of rapid evolution and natural selection. It is also interesting because it confirms that life can adapt to different environments.\\n\\nThe population of these large dragons ranged from about 200 to about 600 in the area where they live. The most striking aspect of this dragon is its ability to rapidly change its vocalizations from \"coo\" to \"thud.\" The Tibetan dragon also has long claws that help it hunt on land and on water. They also are able to reach speeds of up to 50 kilometers per hour. The long and pointed snout allows them to grasp and consume their prey by crushing it between their teeth and then swallowing the flesh. Their tongue is able to carry food items that they swallow whole, such as fruit, seeds, insects, worms,'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rwkv.utils import PIPELINE, PIPELINE_ARGS\n",
    "pipeline = PIPELINE(model, \"20B_tokenizer.json\") \n",
    "ctx = \"\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\"\n",
    "print(ctx, end='')\n",
    "\n",
    "def my_print(s):\n",
    "    print(s, end='', flush=True)\n",
    "\n",
    "args = PIPELINE_ARGS(temperature = 1.0, top_p = 0.7, top_k = 100, # top_k = 0 then ignore\n",
    "                     alpha_frequency = 0.25,\n",
    "                     alpha_presence = 0.25,\n",
    "                     token_ban = [0], # ban the generation of some tokens\n",
    "                     token_stop = [], # stop generation whenever you see any token here\n",
    "                     chunk_len = 256) # split input into chunks to save VRAM (shorter -> slower)\n",
    "\n",
    "pipeline.generate(ctx, token_count=200, args=args, callback=my_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.encode(ctx) == GPT2TokenizerFast(tokenizer_file='20B_tokenizer.json').encode(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 6\n",
      "\n",
      "Loading /home/kyle/HF-MODEL/rwkv-4-pile-1b5/models--BlinkDL--rwkv-4-pile-1b5/snapshots/6ea995eaa87a17af560c9b41ce1a3d92355c5a49/RWKV-4-Pile-1B5-20220903-8040.pth ...\n",
      "Strategy: (total 24+1=25 layers)\n",
      "* cuda [float16, float16], store 25 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  50277  2048 \n",
      "blocks.0.ln1.weight               f16   cuda:0   2048       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   2048       \n",
      "blocks.0.ln2.weight               f16   cuda:0   2048       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   2048       \n",
      "blocks.0.att.time_decay           f32   cuda:0   2048       \n",
      "blocks.0.att.time_first           f32   cuda:0   2048       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   2048       \n",
      "blocks.0.att.key.weight           f16   cuda:0   2048  2048 \n",
      "blocks.0.att.value.weight         f16   cuda:0   2048  2048 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   2048  2048 \n",
      "blocks.0.att.output.weight        f16   cuda:0   2048  2048 \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   2048       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   2048       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   2048  8192 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   2048  2048 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0   8192  2048 \n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.23.ln1.weight              f16   cuda:0   2048       \n",
      "blocks.23.ln1.bias                f16   cuda:0   2048       \n",
      "blocks.23.ln2.weight              f16   cuda:0   2048       \n",
      "blocks.23.ln2.bias                f16   cuda:0   2048       \n",
      "blocks.23.att.time_decay          f32   cuda:0   2048       \n",
      "blocks.23.att.time_first          f32   cuda:0   2048       \n",
      "blocks.23.att.time_mix_k          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_v          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_r          f16   cuda:0   2048       \n",
      "blocks.23.att.key.weight          f16   cuda:0   2048  2048 \n",
      "blocks.23.att.value.weight        f16   cuda:0   2048  2048 \n",
      "blocks.23.att.receptance.weight   f16   cuda:0   2048  2048 \n",
      "blocks.23.att.output.weight       f16   cuda:0   2048  2048 \n",
      "blocks.23.ffn.time_mix_k          f16   cuda:0   2048       \n",
      "blocks.23.ffn.time_mix_r          f16   cuda:0   2048       \n",
      "blocks.23.ffn.key.weight          f16   cuda:0   2048  8192 \n",
      "blocks.23.ffn.receptance.weight   f16   cuda:0   2048  2048 \n",
      "blocks.23.ffn.value.weight        f16   cuda:0   8192  2048 \n",
      "ln_out.weight                     f16   cuda:0   2048       \n",
      "ln_out.bias                       f16   cuda:0   2048       \n",
      "head.weight                       f16   cuda:0   2048 50277 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rwkv_hf import RWKVModel\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast(tokenizer_file='20B_tokenizer.json')\n",
    "bad_review_text = 'George P. Cosmatos\\' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn\\'t win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn\\'t appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\\n\\nDid the reviewer find this movie good or bad? bad'\n",
    "good_review_text = 'George P. Cosmatos\\' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn\\'t win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn\\'t appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\\n\\nDid the reviewer find this movie good or bad? good'\n",
    "model = RWKVModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape = {'input_ids': tensor([[23108,   367,    15, 18084,  2056,   375,     8,   346,    51, 47311,\n",
      "            27,  3973, 14169,  3512,  3719,     3,   310,  6313,  5730,    14,\n",
      "          1020,  9337,   420,    15,   380,  1986,  2077,  4518,  1904,   626,\n",
      "          3330,   253,  2137,   275, 15732,    15,  1583,  4269,  4723,   281,\n",
      "           436,  2586,  4457,   253, 30087,   494,   285,   436,  6440,  7788,\n",
      "           253, 33784,  2926,   273,   253, 12506,    14,   601, 15377,  9647,\n",
      "            15,   380,   760,  3076,  6068,   497,   253,  7038,   273,   253,\n",
      "          5674,    13,   665,  1160,   436,  2137,  5108,    15,   380,  1894,\n",
      "           273,   416, 47311,   310,  3962,   281,  4366,   436,    15,   754,\n",
      "           310,  6685, 50174,    13,   320,  6972,   507,   326,  1982,    14,\n",
      "         34436,  1904,   626, 11435,   285, 17019,   253, 26751,   273,   253,\n",
      "          2014, 15796,    13,   533,   556,  2717,   533, 48655,   323,  4283,\n",
      "          6251,   285, 13557,    15,  6975,  1046,  3085,   326,   809,  1727,\n",
      "           253,  2137,   313,    70,    15,    72,    15,   346,  1231, 27200,\n",
      "         29668,  4670,  2807,   671,   436,   581, 32547,   253,   878,   281,\n",
      "          1918,   247, 28535,  6286,  1921,   323,   253, 13226,   275,  3684,\n",
      "         10497,    15,  1244,   323,   326,  2647,   671,   253,  1921,   323,\n",
      "          1046,  2014,  1982,    14,  7878, 15796,   326,   369,   627,    15,\n",
      "          7820,    13,   416, 47311,  4850,   281,  1379, 25442,   323,   253,\n",
      "         19952,   273,   247,  2644,  5674,    15,   733,   651,   452,   644,\n",
      "          1805,   281,   789,   327,   849,   281,  2968,   342,   253, 12959,\n",
      "            13,  2581,   685, 35582,   731,    15,   346,  4045,   359,   755,\n",
      "           281,  3330,   436,   673,   865,  6279,    13,   368,   513,    15,\n",
      "           187,   187,  8917,   253, 37317,  1089,   436,  6440,  1175,   390,\n",
      "          3076,    32,  3076]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(bad_review_text, return_tensors=\"pt\")\n",
    "print(f\"Input IDs shape = {tokens}\")\n",
    "\n",
    "states = model(tokens[\"input_ids\"])\n",
    "tensor_final_state = states[-1]\n",
    "len(tensor_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape = torch.Size([1, 243])\n",
      "Received a list of 120 tensors, each of shape torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(bad_review_text, return_tensors=\"pt\")\n",
    "print(f\"Input IDs shape = {tokens['input_ids'].shape}\")\n",
    "# tokens\n",
    "\n",
    "states = model(tokens[\"input_ids\"])\n",
    "tensor_final_state = states[-1]\n",
    "print(f\"Received a list of {len(state)} tensors, each of shape {state[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0183, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle-elk-rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
